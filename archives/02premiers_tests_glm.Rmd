---
title: "Untitled"
output: html_document
date: "`r Sys.Date()`"
---

```{r}
# For the accents é ù û etc
options(Encoding="latin1")
# Cleaning the environment
rm(list=ls())
# Getting the paths
source("paths.R",encoding="latin1")
# Setting the current path
path_to_R_folder = file.path(
                             path_to_Savanna_structure_GEDI_folder,
                             "R"
                             )
setwd(path_to_R_folder)
getwd()

# Libraries
library(fst)
library(visdat)
# install.packages("visdat")
library(ggplot2)
# install.packages("betareg")
library(betareg)
# browseURL("https://www.jstatsoft.org/article/view/v034i02")

# Chargement du tableau missing_data_percentages.csv

setwd(file.path(
                path_to_Savanna_structure_GEDI_folder,
                "figures"
                )
      )

missing_data_percentages <- read.csv("missing_data_percentages.csv",row.names=1)

setwd(path_to_R_folder)
```

```{r}
# Normalisation des données sur un exemple

setwd(path_to_GEDI_raw_data)
# print(dir())

name = dir()[16]
# Loading of the table :
corresponding_table = fst::read.fst(name)
name <- substr(name, start = 1, stop = nchar(name) - 4)
# to get rid of the ".fst" in the graph name
print(name)
# "Northern_Congolian"

# # Pour avoir le type des données :

# str(corresponding_table)
# sapply(corresponding_table, class)

# On enlève la variable "ecoregion" pour ne garder que les données numériques :
corresponding_table <- corresponding_table[,-11]
# On va même garder seulement ça pour commencer :
corresponding_table <- corresponding_table[,c("x",
                                              "y",
                                              "canopy_cover",
                                              "fire_freq",
                                              "mean_precip")
                                           ]
# On enlève les valeurs manquantes
corresponding_table <- na.omit(corresponding_table)
print(round(
            missing_data_percentages[name,c("canopy_cover","fire_freq","mean_precip")],
            2)
      )
# Normalisation et standardisation 
corresponding_table[,c("fire_freq","mean_precip")] <- scale(
corresponding_table[,c("fire_freq","mean_precip")],
center=TRUE,scale=TRUE)

# Vérification :
colMeans(corresponding_table)
apply(corresponding_table, MARGIN = 2, sd)
# 2 pour spécifier qu'on fait l'opération sur les colonnes (1 pour ligne)

#########################################################################

# canopy_cover dans [0,1] -> loi beta ?
# Gadget en ligne pour regarder la densité loi beta :
# browseURL("https://mathlets.org/mathlets/beta-distribution/")

# Il n'y a pas de loi beta dans glm :
# glm_result <- glm(
#                   canopy_cover ~ 1 + fire_freq + mean_precip,
#                   family = beta, # ça existe pas
#                   data = corresponding_table
#                   )

corresponding_table <- as.data.frame(corresponding_table)
```

```{r}
glm_result <- betareg(
                      canopy_cover ~ 1 + fire_freq + mean_precip,
                      link = "logit",
                      # link function in the mean model (mu)
                      # logit par défaut ??
                      data = corresponding_table
                      )
# "your dependent variable should take values that are strictly greater than 0 and strictly less than 1; they cannot be equal to 0 or equal to 1" cf :
# browseURL("https://stats.stackexchange.com/questions/496050/why-is-betareg-giving-invalid-dependent-variable-error")

summary(corresponding_table$canopy_cover)
#  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.00000 0.06435 0.13325 0.16026 0.22601 0.97506 

# donc a priori le problème c'est les zéros pour les données "Northern_Congolian"
# sum(corresponding_table[,"canopy_cover"]==0)
# 9017 zéros sur 300 000 lignes

# browseURL("https://mathlets.org/mathlets/beta-distribution/")
```

```{r}
# Regardons si les bornes de canopy_cover sont atteintes pour tous les jeux de données :

setwd(path_to_GEDI_raw_data)

print(dir())
print(length(dir()))

colnames_canopy_cover <- c(
                           "min",
                           "nb_0",
                           "% 0",
                           "max",
                           "nb_1",
                           "1st quart",
                           "median",
                           "3rd quart",
                           "% de cc>0.9",
                           "nb_rows_tot",
                           "nb_rows",
                           "% NA"
                           )

df_canopy_cover <- data.frame(matrix(NA, nrow = length(dir()), ncol = length(colnames_canopy_cover)))

colnames(df_canopy_cover) <- colnames_canopy_cover
rm(colnames_canopy_cover)

for (i in 1:length(dir())){
# for (i in 1:length(dir())){
  
  name = dir()[i]
  corresponding_table = fst::read.fst(name)
  nb_rows_NA_included <- nrow(corresponding_table)
  
  NA_cc_percentage <- round(
                            sum(is.na(corresponding_table$canopy_cover))/nrow(corresponding_table)
                            ,2)
  
  corresponding_table1 <- corresponding_table # all NA included in corresponding_table1
  
  # percentage of NA
  corresponding_table <- corresponding_table[complete.cases(corresponding_table[ , "canopy_cover"]),]
  # get rid of the NA
  nb_rows_NA_excluded <- nrow(corresponding_table)
  
  name <- substr(name, start = 1, stop = nchar(name) - 4)
  # to get rid of the ".fst" in the graph name
  row.names(df_canopy_cover)[i] <- name 
  
  df_canopy_cover[i,] <- c(
                           round(min(corresponding_table[,"canopy_cover"]),4),
                           sum(corresponding_table[,"canopy_cover"]==0),
                           round(sum(corresponding_table[,"canopy_cover"]==0)/nb_rows_NA_excluded,2),
                           round(max(corresponding_table[,"canopy_cover"]),5),
                           round(sum(corresponding_table[,"canopy_cover"]==1),2),
                           round(quantile(corresponding_table[,"canopy_cover"], probs = 0.25),2),
                           round(median(corresponding_table[,"canopy_cover"]),2),
                           round(quantile(corresponding_table[,"canopy_cover"], probs = 0.75),2),
                           round(sum(corresponding_table$canopy_cover>0.9)/nb_rows_NA_excluded,5),
                           format(round(nb_rows_NA_excluded,-2), scientific = TRUE),
                           format(round(nb_rows_NA_included,-2), scientific = TRUE),
                           NA_cc_percentage
                           )
  
}

rm(nb_rows_NA_included)
rm(corresponding_table)
rm(corresponding_table1)

View(df_canopy_cover)

# Get back to the R folder
setwd(path_to_R_folder)
```

```{r}
# Alors pourquoi y a-t-il des tableaux avec Inf en min et max
setwd(path_to_GEDI_raw_data)

corresponding_table = fst::read.fst("Horn_of.fst")
# corresponding_table <- na.omit(corresponding_table)
summary(corresponding_table$canopy_cover)
min(corresponding_table$canopy_cover)

# Le problème, c'est que si on fait :
# corresponding_table <- na.omit(corresponding_table)
# pour enlever les valeurs manquantes de canopy_cover,
# comme pour Horn_of et Serengueti_volcanic, on a 100% de données de feu manquantes, ça les enlève aussi, donc il faut uniquement enlever les valeurs manquantes correspondant à canopy_cover pour voir les min et max :

corresponding_table <- corresponding_table[complete.cases(corresponding_table[ , "canopy_cover"]),]

# complete.cases allows partial selection by including only certain columns of the dataframe" d'après :
# browseURL("https://stackoverflow.com/questions/4862178/remove-rows-with-all-or-some-nas-missing-values-in-data-frame")

# Cela étant fait, si jamais on a 100% de NA pour le feu on ne peut pas faire de régression ce la canopy_cover par rapport au feu de toutes façons.
```


```{r}
# Regardons si les bornes de rh98 sont atteintes pour tous les jeux de données :

setwd(path_to_GEDI_raw_data)

print(dir())
print(length(dir()))

colnames_rh98 <- c(
                           "min",
                           "nb_0",
                           "% 0",
                           "max",
                           "nb_1",
                           "1st quart",
                           "median",
                           "3rd quart",
                           "% de rh98>25",
                           "nb_rows_tot",
                           "nb_rows",
                           "% NA"
                           )

df_rh98 <- data.frame(matrix(NA, nrow = length(dir()), ncol = length(colnames_rh98)))

colnames(df_rh98) <- colnames_rh98
rm(colnames_rh98)

for (i in 1:length(dir())){

  name = dir()[i]
  corresponding_table = fst::read.fst(name)
  nb_rows_NA_included <- nrow(corresponding_table)
  
  NA_cc_percentage <- round(
                            sum(is.na(corresponding_table$canopy_cover))/nrow(corresponding_table)
                            ,2)
  
  corresponding_table1 <- corresponding_table # all NA included in corresponding_table1
  
  # percentage of NA
  corresponding_table <- corresponding_table[complete.cases(corresponding_table[ , "rh98"]),]
  # get rid of the NA
  nb_rows_NA_excluded <- nrow(corresponding_table)
  
  name <- substr(name, start = 1, stop = nchar(name) - 4)
  # to get rid of the ".fst" in the graph name
  row.names(df_rh98)[i] <- name 
  
  df_rh98[i,] <- c(
                   round(min(corresponding_table[,"rh98"]),2),
                   sum(corresponding_table[,"rh98"]==0),
                   round(sum(corresponding_table[,"rh98"]==0)/nb_rows_NA_excluded,2),
                   round(max(corresponding_table[,"rh98"]),3),
                   round(sum(corresponding_table[,"rh98"]==1),2),
                   round(quantile(corresponding_table[,"rh98"], probs = 0.25),2),
                   round(median(corresponding_table[,"rh98"]),2),
                   round(quantile(corresponding_table[,"rh98"], probs = 0.75),2),
                   round(sum(corresponding_table$rh98>25)/nb_rows_NA_excluded,5),
                   format(round(nb_rows_NA_excluded,-2), scientific = TRUE),
                   format(round(nb_rows_NA_included,-2), scientific = TRUE),
                   NA_cc_percentage
                   )
  

}

rm(nb_rows_NA_included)
rm(corresponding_table)
rm(corresponding_table1)

View(df_rh98)

# Get back to the R folder
setwd(path_to_R_folder)
```

```{r}

# Sauvegarde des deux tableaux résumant les formes respectives de canop_cover et rh98

setwd(file.path(
                path_to_Savanna_structure_GEDI_folder,
                "figures"
                )
      )

# write.csv(df_canopy_cover,"Summaries_canopy_cover.csv")
# write.csv(df_rh98,"Summaries_rh98.csv")

setwd(path_to_R_folder)

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


